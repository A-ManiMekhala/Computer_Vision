{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqFrC5lB72sQVqTB/qwzKx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-ManiMekhala/Code_debug/blob/main/Image_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cZe8p-AyxJ0",
        "outputId": "1d2b67af-c83a-4b25-edb8-850e36e06311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Human-Segmentation-Dataset' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Vikramshenoy97/Human-Segmentation-Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import Adam, AdamW, SGD"
      ],
      "metadata": {
        "id": "_kkKGo0l0Hsi"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "  def __init__(self, image_dir, mask_dir):\n",
        "    self.image_dir=image_dir\n",
        "    self.mask_dir=mask_dir\n",
        "    self.transform = transforms.Compose([\n",
        "        transforms.Resize((512,512)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    valid_extension = {\".jpg\",\"jpeg\",\".png\"}\n",
        "    ##Filter condition\n",
        "    self.images= [f for f in os.listdir(image_dir) if os.path.splitext(f)[1].lower() in valid_extension]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    ##we are retriving images based on index\n",
        "    img_path= os.path.join(self.image_dir,self.images[idx])\n",
        "    ##for eg: 1.jpg--> 1, jpg\n",
        "    name,text= os.path.splitext(self.images[idx])\n",
        "    ##Iam going to look for this .png in mask directory to get correct mask\n",
        "    ## when I ask my data loader to get me an index of five in getitem, it will look\n",
        "    ##for the image with the index of five and that particular name, with that png will be\n",
        "    ##the mask path.\n",
        "    mask_path= os.path.join(self.mask_dir,f\"{name}.png\")\n",
        "\n",
        "    image=Image.open(img_path).convert(\"RGB\")\n",
        "    mask= Image.open(mask_path).convert(\"L\") ## Lightness\n",
        "\n",
        "    image=self.transform(image)\n",
        "    mask=self.transform(mask)\n",
        "\n",
        "    ##to get accurate mask\n",
        "    mask= (mask>0.5).float()\n",
        "    return image,mask\n",
        "\n",
        "\n",
        "    ##our data set is ready\n"
      ],
      "metadata": {
        "id": "QyeFOko40iX1"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader: It will help us to retrieve data in batches which we will then use\n",
        "# for model training.\n",
        "\n",
        "def get_dataloader(image_dir, mask_dir, batch_size=2, shuffle=True):\n",
        "    dataset = SegmentationDataset(image_dir, mask_dir)  # â† pass the args here\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n"
      ],
      "metadata": {
        "id": "_6ejHhmg5xG1"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv_op = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv_op(x)\n"
      ],
      "metadata": {
        "id": "wDCPq-DK5412"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownSample(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv= DoubleConv(in_channels,out_channels)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    down= self.conv(x)\n",
        "    p= self.pool(down)\n",
        "\n",
        "    return down,p\n",
        "\n"
      ],
      "metadata": {
        "id": "3zW2trBC7uv_"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpSample(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.up= nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n",
        "    self.conv=DoubleConv(in_channels, out_channels)\n",
        "\n",
        "  def forward(self,x1,x2):\n",
        "      ##Here we are utilizing 2 parts --> previous encoder part and also the upsampling part.\n",
        "    x1= self.up(x1)\n",
        "      ##x2--> belongs to the down part that returned by the downsample.\n",
        "\n",
        "      ## Now concatinating x1, x2\n",
        "    x = torch.cat([x1,x2],1)\n",
        "    return self.conv(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rDD2OLTH9J8f"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "  ## arranging operations line by line\n",
        "  def __init__(self, in_channels,num_classes):\n",
        "    super().__init__()\n",
        "    self.down_conv_1= DownSample(in_channels,64)\n",
        "    self.down_conv_2= DownSample(64,128)\n",
        "    self.down_conv_3= DownSample(128,256)\n",
        "    self.down_conv_4= DownSample(256,512)\n",
        "\n",
        "    self.bottle_neck = DoubleConv(512, 1024)\n",
        "\n",
        "    self.up_conv_1= UpSample(1024,512)\n",
        "    self.up_conv_2= UpSample(512,256)\n",
        "    self.up_conv_3= UpSample(256,128)\n",
        "    self.up_conv_4= UpSample(128,64)\n",
        "\n",
        "    self.out= nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    down_1, p1 = self.down_conv_1(x)\n",
        "    down_2, p2 = self.down_conv_2(p1)\n",
        "    down_3, p3 = self.down_conv_3(p2)\n",
        "    down_4, p4 = self.down_conv_4(p3)\n",
        "\n",
        "    b= self.bottle_neck(p4)\n",
        "\n",
        "    up_1= self.up_conv_1(b, down_4)\n",
        "    up_2= self.up_conv_2(up_1,down_3)\n",
        "    up_3= self.up_conv_3(up_2, down_2)\n",
        "    up_4= self.up_conv_4(up_3, down_1)\n",
        "\n",
        "    out= self.out(up_4)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s1OZcaHj8962"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##loss function\n",
        "class DiceLoss(nn.Module):\n",
        "  def __init__(self, smooth=1e-6):   ## smoooth --> because , we cannot get zero division error\n",
        "    super(DiceLoss, self).__init__()\n",
        "    self.smooth= smooth\n",
        "\n",
        "  def forward(self,inputs, targets):\n",
        "    inputs=inputs.view(-1)\n",
        "    targets= targets.view(-1)\n",
        "\n",
        "    intersection = (inputs* target).sum()\n",
        "    dice_score = (2. * intersection + self. smooth)/ (inputs.sum()+ targets.sum() + self.smooth)\n",
        "\n",
        "\n",
        "    return 1- dice_score\n"
      ],
      "metadata": {
        "id": "XgqOU9c9CCqS"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BCEWithDiceLoss(nn.Module):\n",
        "  def __init__ (self, smooth=1e-6):\n",
        "    super(BCEWithDiceLoss, self).__init__()\n",
        "    self.bce= nn.BCEWithLogitsLoss()\n",
        "    self.dice= DiceLoss()\n",
        "\n",
        "  def forward(self, inputs, targets):\n",
        "    bce_loss= self.bce(inputs, targets)\n",
        "    dice_loss= self.dice(inputs, targets)\n",
        "    return 0.5 * bce_loss + dice_loss"
      ],
      "metadata": {
        "id": "LkwPpIQOIEnI"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "def train(model, dataloader, epochs=2, lr=0.01,save_path=\"unet_model\", load_path=None):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  if load_path and os.path.exists(load_path):\n",
        "    print(f\"Loading model weights from {load_path}\")\n",
        "    model.load_state_dict(torch.load(load_path, map_location=device))\n",
        "  else:\n",
        "    print(f\"No checkpoint found, training from scratch.\")\n",
        "\n",
        "  print(device)\n",
        "  model.to(device)\n",
        "\n",
        "  criterion = BCEWithDiceLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  optimizer = SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss=0\n",
        "\n",
        "    for images, masks in dataloader:\n",
        "      images, masks = images.to(device), masks.to(device)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(images)\n",
        "\n",
        "      loss = criterion(output, masks)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss /len(dataloader)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, LR:{lr} \")\n",
        "\n",
        "    if epoch %10 ==0 and epoch >0:\n",
        "      torch.save(model.state_dict(), f\"{save_path}.pth\")\n",
        "\n",
        "  torch.save(model.state_dict(), f\"{save_path}_final.pth\")\n",
        "  print(f\"Model Saved to {save_path}\")"
      ],
      "metadata": {
        "id": "HLJ-Y2fqJB2v"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = get_dataloader(\"/content/Human-Segmentation-Dataset/Training_Images\", \"/content/Human-Segmentation-Dataset/Ground_Truth\", batch_size=8, shuffle=True)\n"
      ],
      "metadata": {
        "id": "TzTcCpkuUfSl"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet(in_channels=3, num_classes=1)"
      ],
      "metadata": {
        "id": "2KBb5WY9MBV2"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, dataloader, epochs=2, lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPBc5D5SV1IO",
        "outputId": "499a955c-c571-4a0a-e27e-7bb7adbd37b5"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found, training from scratch.\n",
            "cuda\n",
            "Epoch [1/2], Loss: 0.6602, LR:0.001 \n",
            "Epoch [2/2], Loss: 0.6590, LR:0.001 \n",
            "Model Saved to unet_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load model and predict with stats\n",
        "def predict(model_path, input_image_path):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load model\n",
        "    model = UNet(in_channels=3, num_classes=1)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Track start time\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    # Image preprocessing\n",
        "    preprocess_start_time = time.time()\n",
        "    image = Image.open(input_image_path).convert(\"RGB\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((512, 512)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "    preprocess_end_time = time.time()\n",
        "\n",
        "    # Model inference\n",
        "    inference_start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        output = torch.sigmoid(output)\n",
        "    inference_end_time = time.time()\n",
        "\n",
        "    # Postprocessing\n",
        "    postprocess_start_time = time.time()\n",
        "    mask = output.squeeze(0).squeeze(0).cpu().numpy()\n",
        "    mask = (mask > 0.4).astype(np.uint8) * 255\n",
        "    mask_image = Image.fromarray(mask)\n",
        "\n",
        "    combined = Image.new(\"RGB\", (512 * 2, 512))\n",
        "    combined.paste(image.resize((512, 512)), (0, 0))\n",
        "    combined.paste(mask_image.convert(\"RGB\"), (512, 0))\n",
        "    combined.save(\"output.jpg\")\n",
        "    postprocess_end_time = time.time()\n",
        "\n",
        "    # Calculate timing stats\n",
        "    total_end_time = time.time()\n",
        "\n",
        "    preprocess_time = preprocess_end_time - preprocess_start_time\n",
        "    inference_time = inference_end_time - inference_start_time\n",
        "    postprocess_time = postprocess_end_time - postprocess_start_time\n",
        "    total_time = total_end_time - total_start_time\n",
        "\n",
        "    # Print stats\n",
        "    print(\"\\nPrediction completed! Stats:\")\n",
        "    print(f\"  Image Preprocessing Time: {preprocess_time:.4f} seconds\")\n",
        "    print(f\"  Model Inference Time: {inference_time:.4f} seconds\")\n",
        "    print(f\"  Postprocessing Time: {postprocess_time:.4f} seconds\")\n",
        "    print(f\"  Total Prediction Time: {total_time:.4f} seconds\")\n",
        "    print(\"Prediction saved as output.jpg\")\n",
        "\n"
      ],
      "metadata": {
        "id": "bs_27jkJX_MA"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model_path=\"/content/unet_model_final.pth\", input_image_path=\"/content/Human-Segmentation-Dataset/Training_Images/101.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugLh5nDdZWOD",
        "outputId": "360c4edf-f11e-44e2-a739-cf487809ea54"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Prediction completed! Stats:\n",
            "  Image Preprocessing Time: 0.0100 seconds\n",
            "  Model Inference Time: 0.0022 seconds\n",
            "  Postprocessing Time: 0.1153 seconds\n",
            "  Total Prediction Time: 0.1275 seconds\n",
            "Prediction saved as output.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tfsaj7ouaKVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model_path=\"/content/unet_model_80.pth\", input_image_path=\"/content/Human-Segmentation-Dataset/Training_Images/101.jpg\")"
      ],
      "metadata": {
        "id": "Lzj0thE7aLnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LnctR5POaHc_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}